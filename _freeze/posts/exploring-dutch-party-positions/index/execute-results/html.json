{
  "hash": "370398b75fb2b7103c471e137604181c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Exploring Dutch Party Positions\"\ndescription: \"Scraping and analyzing data from the Stemwijzer website.\"\nauthor: \"Aswin van Woudenberg\"\ndate: \"2025-10-21\"\ncategories: [programming, python, pandas, sklearn, machine learning]\ntoc: true\n---\n\n\nDutch general elections are coming up at the end of this month. A lot of people in the Netherlands use the [Stemwijzer](https://www.stemwijzer.nl) website to figure out which political party to vote for. You answer 30 statements with *Eens* (agree), *Oneens* (disagree), or *Geen van beide* (neutral), and it shows which parties align most with your answers.\n\n![](stemwijzer.png)\n\nFor each statement you can see which political parties agree, disagree, or are neutral about it, and why.\n\nStill, even with tools like this, voting often feels like picking the least bad option. That frustration got me wondering: how different are these parties, really? And in what way? To explore that, I scraped the positions of the various parties on those statements to do some data exploration. I’ll visualize parties in 2D using t-SNE to see if any clusters arise. I’ll also perform a PCA and try to interpret the first two principal components and map them to underlying ideologies.\n\n## How the data was collected\n\nI wrote a Python script that scrapes the party responses to the 30 statements from the Stemwijzer website. For each statement we get:\n\n* The theme (broad topic label)\n* The statement text\n* A short info blurb\n* Each party's stance: *Eens* (agree), *Oneens* (disagree), *Geen van beide* (neutral)\n* A short explanation per party (why they answered that way)\n\nThe script saves the scraped data as `tweedekamer2025.json`.\n\n## Importing libraries\n\nWe are going to need the following dependencies. \n\n::: {#5574f66a .cell execution_count=1}\n``` {.python .cell-code}\nfrom PIL import Image\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nltk\nimport json\n```\n:::\n\n\n## Loading the JSON\n\nWe start our analysis by loading the JSON file produced by the scraper. Each entry contains a statement plus per‑party responses. We’ll reshape it into a dataframe where each row is one issue and columns hold party positions and their explanation texts.\n\n::: {#21462de3 .cell execution_count=2}\n``` {.python .cell-code}\nwith open('tweedekamer2025.json', 'r', encoding='utf-8') as f:\n    data = json.load(f)\n\n# We flatten the 'positions' list, keeping 'theme', 'title', and 'info' as identifying metadata.\ndf_long = pd.json_normalize(\n    data, \n    record_path='positions', \n    meta=['theme', 'title', 'info']\n)\n\n# Rename the columns for clarity before pivoting\ndf_long['position_col'] = df_long['party'] + '_position'\ndf_long['explanation_col'] = df_long['party'] + '_explanation'\n\n# We create one table for 'position' data\ndf_position = df_long.pivot_table(\n    index=['theme', 'title', 'info'], \n    columns='position_col', \n    values='position', \n    aggfunc='first'\n).reset_index()\n\n# We create a second table for 'explanation' data\ndf_explanation = df_long.pivot_table(\n    index=['theme', 'title', 'info'], \n    columns='explanation_col', \n    values='explanation', \n    aggfunc='first'\n).reset_index()\n\n# We merge on the common descriptive columns: 'theme', 'title', and 'info'\ndf_merged = pd.merge(\n    df_position, \n    df_explanation, \n    on=['theme', 'title', 'info']\n)\n\n# Sort the columns to get party columns adjacent (e.g., SP_position, SP_explanation)\nparty_cols = [col for col in df_merged.columns if col not in ['theme', 'title', 'info']]\nparty_cols.sort(key=lambda x: (x.split('_')[0], x.split('_')[1] == 'explanation'))\n\n# Combine the descriptive columns with the sorted party columns\nfinal_columns = ['theme', 'title', 'info'] + party_cols\ndf_final = df_merged[final_columns]\n```\n:::\n\n\n## A quick peek at the data\n\nBefore diving into visualizations let’s sanity‑check what we have so far:\n\nLet's look at the first few rows.\n\n::: {#a1d80a47 .cell .column-screen-inset execution_count=3}\n``` {.python .cell-code}\ndf_final.head()\n```\n\n::: {.cell-output .cell-output-display execution_count=123}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>theme</th>\n      <th>title</th>\n      <th>info</th>\n      <th>50PLUS_position</th>\n      <th>50PLUS_explanation</th>\n      <th>BBB_position</th>\n      <th>BBB_explanation</th>\n      <th>BIJ1_position</th>\n      <th>BIJ1_explanation</th>\n      <th>BVNL_position</th>\n      <th>...</th>\n      <th>SP_position</th>\n      <th>SP_explanation</th>\n      <th>VVD_position</th>\n      <th>VVD_explanation</th>\n      <th>Volt_position</th>\n      <th>Volt_explanation</th>\n      <th>Vrede voor Dieren_position</th>\n      <th>Vrede voor Dieren_explanation</th>\n      <th>Vrij Verbond_position</th>\n      <th>Vrij Verbond_explanation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aanwezigheid bij demonstratie</td>\n      <td>De politie moet bijhouden wie aanwezig is bij ...</td>\n      <td>In Nederland heb je het recht om te demonstrer...</td>\n      <td>Eens</td>\n      <td>Betere handhaving en strenger optreden bij ove...</td>\n      <td>Oneens</td>\n      <td>Standaard moeten bijhouden wie een verboden de...</td>\n      <td>Oneens</td>\n      <td>Iedereen moet veilig kunnen demonstreren. Het ...</td>\n      <td>Oneens</td>\n      <td>...</td>\n      <td>Oneens</td>\n      <td>Demonstreren is een grondrecht. Iedereen heeft...</td>\n      <td>Eens</td>\n      <td>De VVD wil dat de politie alle mogelijkheden k...</td>\n      <td>Oneens</td>\n      <td>Volt beschermt het recht op protest. Demonstra...</td>\n      <td>Oneens</td>\n      <td>Demonstratierecht is een groot goed.</td>\n      <td>Oneens</td>\n      <td>Vrij Verbond kiest voor maximale bescherming v...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Abortus</td>\n      <td>Abortus moet uit het Wetboek van Strafrecht .</td>\n      <td>Abortus is het afbreken van een zwangerschap d...</td>\n      <td>Eens</td>\n      <td>50PLUS ziet abortus niet als strafrecht maar m...</td>\n      <td>Oneens</td>\n      <td>Abortus hoort in het Wetboek van Strafrecht th...</td>\n      <td>Eens</td>\n      <td>Abortus is een mensenrecht en hoort bij basisg...</td>\n      <td>Oneens</td>\n      <td>...</td>\n      <td>Eens</td>\n      <td>Abortuszorg is zorg en hoort daarom niet thuis...</td>\n      <td>Eens</td>\n      <td>Abortus is geen misdrijf. Als VVD vinden we he...</td>\n      <td>Eens</td>\n      <td>Volt vindt dat vrouwen het recht hebben om ove...</td>\n      <td>Eens</td>\n      <td>Zelfbeschikking is geen misdaad maar een recht.</td>\n      <td>Eens</td>\n      <td>Abortus is een medische keuze, geen misdaad. V...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bouwen op landbouwgrond</td>\n      <td>De regering moet het bouwen van woningen op la...</td>\n      <td>Gemeentes die woningen willen laten bouwen, mo...</td>\n      <td>Eens</td>\n      <td>Als een paar % van de totale landbouwgrond voo...</td>\n      <td>Oneens</td>\n      <td>Onze vruchtbare landbouwgrond is waardevol. BB...</td>\n      <td>Eens</td>\n      <td>Met name de (melk)veehouderij neemt ontzettend...</td>\n      <td>Oneens</td>\n      <td>...</td>\n      <td>Eens</td>\n      <td>De woningnood is groot en vraagt om nieuwe bou...</td>\n      <td>Eens</td>\n      <td>De VVD wil flink schrappen in het aantal bouwr...</td>\n      <td>Eens</td>\n      <td>Volt wil sneller woningen bouwen, ook op landb...</td>\n      <td>Eens</td>\n      <td>We willen landbouwgrond voor 90% omzetten in n...</td>\n      <td>Eens</td>\n      <td>Meer woningen zijn hard nodig. Laat grondeigen...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Controle op religieuze les</td>\n      <td>De overheid moet strenger controleren wat jong...</td>\n      <td>De overheid heeft regels gemaakt voor scholen ...</td>\n      <td>Eens</td>\n      <td>Onderwijs controle wordt uitgevoerd door de in...</td>\n      <td>Eens</td>\n      <td>Buitenlandse mogendheden steken graag hun lang...</td>\n      <td>Oneens</td>\n      <td>De surveillance van religieuze groepen belemme...</td>\n      <td>Eens</td>\n      <td>...</td>\n      <td>Eens</td>\n      <td>Iedereen mag geloven wat hij wil, maar onderwi...</td>\n      <td>Eens</td>\n      <td>Voor het aanleren van onvrije waarden is in ge...</td>\n      <td>Oneens</td>\n      <td>Volt staat voor gelijke behandeling. Discrimin...</td>\n      <td>Oneens</td>\n      <td>Nederland heeft vrijheid van godsdienst.</td>\n      <td>Oneens</td>\n      <td>Vrijheid van onderwijs en geloof staat centraa...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Eigen risico zorgverzekering</td>\n      <td>Het eigen risico bij zorgverzekeringen wordt p...</td>\n      <td>In Nederland ben je verplicht een zorgverzeker...</td>\n      <td>Oneens</td>\n      <td>Dit leidt tot toename koopkracht. Zeer wenseli...</td>\n      <td>Oneens</td>\n      <td>Het is belangrijk dat zorg toegankelijk en bet...</td>\n      <td>Oneens</td>\n      <td>We zetten een Nationaal Zorgfonds op dat de pr...</td>\n      <td>Eens</td>\n      <td>...</td>\n      <td>Oneens</td>\n      <td>Het eigen risico is een boete op ziek zijn. Da...</td>\n      <td>Eens</td>\n      <td>Het eigen risico is voor ons belangrijk om de ...</td>\n      <td>Eens</td>\n      <td>Volt wil dat zorg betaalbaar blijft voor ieder...</td>\n      <td>Oneens</td>\n      <td>De zorg moet voor iedereen betaalbaar zijn.</td>\n      <td>Eens</td>\n      <td>Vrij Verbond kiest voor een eerlijk zorgstelse...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 51 columns</p>\n</div>\n```\n:::\n:::\n\n\nEach row equals one statement (issue) from Stemwijzer.\nFor every party we have two columns: one categorical position (`_position`) and one short text explanation (`_explanation`).\n\nWe should have 30 issues for 24 parties.\n\n::: {#4065f176 .cell execution_count=4}\n``` {.python .cell-code}\nnum_parties = len([col for col in df_position.columns if col.endswith('_position')])\nnum_issues = df_position.shape[0]\n\nprint(f\"Number of parties: {num_parties}\")\nprint(f\"Number of issues: {num_issues}\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nNumber of parties: 24\nNumber of issues: 30\n```\n:::\n:::\n\n\n## What do the various parties think about each issue?\n\nWe’ll plot a bar chart per statement showing counts of parties that agree, disagree, or stay neutral. \n\nWe add logos to each bar so we can see which party thinks what. \n\n::: {#4b41e60c .cell execution_count=5}\n``` {.python .cell-code}\n# List of parties in the order they appear in the image\nparties = [\n    'PVV', 'GroenLinks-PvdA', 'VVD', 'NSC', 'D66', 'BBB', 'CDA', \n    'SP', 'DENK', 'Partij voor de Dieren', 'FvD', 'SGP', 'ChristenUnie', \n    'Volt', 'JA21', 'Vrede voor Dieren', 'BVNL', 'BIJ1', 'Libertaire Partij', \n    '50PLUS', 'Piratenpartij', 'FNP', 'Vrij Verbond', 'De Linie'\n]\n\n# Load the image\nimg = Image.open('parties.png')\n\n# Get image dimensions\nwidth, height = img.size\n\n# Find the logo's height:\nnum_parties = len(parties)\nlogo_height = height // num_parties\n\n# Cut each logo and store in a dictionary\nparty_logos = {}\nfor i in range(num_parties):\n    top = i * logo_height\n    bottom = (i + 1) * logo_height\n    logo = img.crop((0, top, width, bottom))\n    party_logos[parties[i]] = logo\n```\n:::\n\n\nNext we create a bar chart for each of the 30 issues.\n\n::: {#642ec387 .cell .column-screen-inset-right execution_count=6}\n``` {.python .cell-code}\n# Get all party position columns\nposition_cols = [col for col in df_position.columns if col.endswith('_position')]\n\n# Plotting\nfig, axes = plt.subplots(10, 3, figsize=(12, 60), constrained_layout=True)\naxes = axes.flatten()\n\ndef text_wrap(text, width=40):\n    \"\"\"Wrap text at word boundaries.\"\"\"\n    import textwrap\n    return \"\\n\".join(textwrap.wrap(text, width=width))\n\ndef bold_text_with_spaces(text):\n    \"\"\"Make text bold while preserving spaces\"\"\"\n    return ' '.join(f'$\\\\mathbf{{{word}}}$' for word in text.split())\n\ndef add_party_logos(ax, row):\n    \"\"\"Add party logos for each position\"\"\"\n    y_offsets = [0] * 3  # Track y-offset for each column (Eens, Oneens, Geen van beide)\n    \n    # First, count how many parties are in each position to calculate bar heights\n    counts = {'Eens': 0, 'Oneens': 0, 'Geen van beide': 0}\n    for pos in [val for col, val in row.items() if col.endswith('_position')]:\n        if pd.notna(pos):\n            counts[pos] += 1\n    \n    # Draw the bars\n    x = np.arange(3)\n    ax.bar(x, [((counts['Eens'] + 1) // 2) * 2.2, ((counts['Oneens'] + 1) // 2) * 2.2, ((counts['Geen van beide'] + 1) // 2) * 2.2], \n           color='white', edgecolor=['green', 'red', 'grey'], alpha=0.8, width=0.65)\n    # Add counts to the top of each bar (except when count is 0)\n    for idx, (label, count) in enumerate(counts.items()):\n        if count > 0:\n            ax.text(\n                idx, \n                ((count + 1) // 2) * 2.2 + 0.2, \n                str(count), \n                ha='center', \n                va='bottom', \n                fontsize=12, \n                fontweight='bold'\n            )\n    \n    # Now add logos\n    for party, pos in [(col.replace('_position', ''), val) for col, val in row.items() if col.endswith('_position')]:\n        if party in party_logos and pd.notna(pos):\n            if pos == 'Eens':\n                x = 0\n            elif pos == 'Oneens':\n                x = 1\n            else:  # Geen van beide\n                x = 2\n                \n            # Convert logo to array and add to plot\n            logo = party_logos[party]\n            imagebox = OffsetImage(logo, zoom=0.2)\n            if y_offsets[x] % 2 == 0:\n                shift_x = x + 0.15\n            else:\n                shift_x = x - 0.15\n            y = (y_offsets[x] // 2) * 2.2 + 1.1\n            ab = AnnotationBbox(imagebox, (shift_x, y),\n                              frameon=False,\n                              box_alignment=(0.5, 0.5))\n            ax.add_artist(ab)\n            y_offsets[x] += 1\n\nfor i, ax in enumerate(axes):\n    if i < len(df_position.index):\n        row = df_position.iloc[i]\n        \n        # Set theme as main title and wrapped title as subtitle\n        ax.set_title(\n            f\"{bold_text_with_spaces(row['theme'])}\\n{text_wrap(row['title'])}\", \n            fontsize=10, \n            pad=15,\n            wrap=True\n        )\n        \n        # Set up the axes\n        ax.set_xlim(-0.5, 2.5)\n        ax.set_ylim(0.0, len(position_cols))\n        ax.set_xticks([0, 1, 2])\n        ax.set_xticklabels(['Eens', 'Oneens', 'Geen van beide'], rotation=0)\n        \n        # Add party logos\n        add_party_logos(ax, row)\n        \n        # Remove y-axis\n        ax.set_yticks([])\n    else:\n        ax.axis('off')\n\nplt.suptitle('Distribution of party positions per theme', fontsize=16)\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=1163 height=5771}\n:::\n:::\n\n\nThe theme of **Illegaal verblijf** (\"Illegal stay\") is the most divisive issue, with an even split of parties agreeing and disagreeing. Conversely, the **Heffing op plastic** (\"Plastic tax\") is the least divisive, showing a strong consensus among most parties.\n\n## What reasons do parties give when they explain their positions?\n\nTo get an idea of what some reasons are for agreeing or disagreeing with a statement I'll plot a word cloud for each issue. In word clouds the size of a word indicates how frequently this word is used. \n\nWe remove stopwords to make sure the word clouds aren't crowded with irrelevant words.\n\n::: {#003057e8 .cell execution_count=7}\n``` {.python .cell-code}\n# Ensure NLTK stopwords are downloaded and get Dutch stopwords\nnltk.download('stopwords')\ndutch_stopwords = set(stopwords.words('dutch'))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n[nltk_data] Downloading package stopwords to /home/aswin/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n```\n:::\n:::\n\n\nI'm color coding the words as follows: A word is shown in green if it's more frequently used among agreeing parties and in red if disagreeing parties use this word more.\n\n::: {#d65f56ae .cell execution_count=8}\n``` {.python .cell-code}\ndef generate_color_func(agree_words, disagree_words):\n    \"\"\"Generate a color function based on word frequencies in agree/disagree groups\"\"\"\n    def color_func(word, **kwargs):\n        # Get frequencies (default to 0 if word not in dict)\n        agree_freq = agree_words.get(word, 0)\n        disagree_freq = disagree_words.get(word, 0)\n        \n        # Calculate ratio (avoiding division by zero)\n        total = agree_freq + disagree_freq\n        if total == 0:\n            return 'grey'\n        \n        ratio = agree_freq / total\n        \n        # Create RGB color based on ratio (green to red gradient)\n        r = int(255 * (1 - ratio))\n        g = int(255 * ratio)\n        b = 0\n        \n        return f'rgb({r}, {g}, {b})'\n    return color_func\n\ndef create_word_frequencies(text_list):\n    \"\"\"Create word frequency dictionary from list of texts\"\"\"\n    from collections import Counter\n    import string\n    \n    # Create translation table to remove punctuation\n    translator = str.maketrans('', '', string.punctuation)\n    \n    words = []\n    for text in text_list:\n        if isinstance(text, str):\n            # Remove punctuation and split into words\n            clean_text = text.translate(translator)\n            # Split text into words and filter out stopwords\n            words.extend([word.lower() for word in clean_text.split() \n                         if word.lower() not in dutch_stopwords \n                         and len(word) > 2])\n    return Counter(words)\n```\n:::\n\n\n::: {#5292735d .cell .column-screen-inset-right execution_count=9}\n``` {.python .cell-code}\n# Create word clouds for each issue\nfig, axes = plt.subplots(6, 5, figsize=(18, 23))\naxes = axes.flatten()\n\nfor idx, (_, row) in enumerate(df_final.iterrows()):\n    if idx >= len(axes):\n        break\n        \n    # Get explanations for parties that agree and disagree\n    agree_explanations = []\n    disagree_explanations = []\n    \n    for party in parties:\n        pos_col = f'{party}_position'\n        exp_col = f'{party}_explanation'\n        \n        if pos_col in row and exp_col in row and pd.notna(row[pos_col]) and pd.notna(row[exp_col]):\n            if row[pos_col] == 'Eens':\n                agree_explanations.append(row[exp_col])\n            elif row[pos_col] == 'Oneens':\n                disagree_explanations.append(row[exp_col])\n    \n    # Create word frequencies for each group\n    agree_words = create_word_frequencies(agree_explanations)\n    disagree_words = create_word_frequencies(disagree_explanations)\n    \n    # Combine all words for the word cloud\n    all_words = {}\n    for word in set(list(agree_words.keys()) + list(disagree_words.keys())):\n        all_words[word] = max(agree_words.get(word, 0), disagree_words.get(word, 0))\n    \n    if all_words:  # Only create word cloud if we have words\n        # Create and generate word cloud\n        wc = WordCloud(width=400, height=300, background_color='white', \n                      color_func=generate_color_func(agree_words, disagree_words),\n                      max_words=50)\n        wc.generate_from_frequencies(all_words)\n        \n        # Display word cloud\n        axes[idx].imshow(wc, interpolation='bilinear')\n        axes[idx].axis('off')\n        axes[idx].set_title(\n            f\"{bold_text_with_spaces(row['theme'])}\\n{text_wrap(row['title'])}\", \n            fontsize=10, \n            pad=15,\n            wrap=True\n        )\n\n# Remove empty subplots\nfor idx in range(len(df_final), len(axes)):\n    axes[idx].axis('off')\n\nplt.suptitle('Words used in party explanations\\n(Green: Words from agreeing parties, Red: Words from disagreeing parties)', \n             fontsize=16, y=0.99)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-10-output-1.png){width=1718 height=2167}\n:::\n:::\n\n\nWhen we, for instance, look at the word cloud for the issue of **kerncentrales** (\"nuclear power plants\"), parties that support building extra nuclear power plants, use words like **reliable**, **stable**, and **clean**, while opponents use words like **costly**, and **slow** refering to the building process.\n\n## How similarly do parties answer across all 30 statements? \n\nFor each pair we compute the % of statements where both gave the same response (agree, disagree, or neutral). \n\n::: {#b976f555 .cell execution_count=10}\n``` {.python .cell-code}\n# Get the raw positions (without encoding)\ndf_positions = df_position[position_cols]\n\n# Clean up party names by removing '_position' suffix\nparty_names = [col.replace('_position', '') for col in position_cols]\n\n# Initialize agreement matrix with zeros, explicitly setting dtype to float64\nagreement_matrix = pd.DataFrame(0.0, index=party_names, columns=party_names, dtype='float64')\n\n# Calculate agreement percentages\nfor i, party1 in enumerate(position_cols):\n    for j, party2 in enumerate(position_cols):\n        # Get positions for both parties where neither is null\n        mask = df_positions[party1].notna() & df_positions[party2].notna()\n        positions1 = df_positions[party1][mask]\n        positions2 = df_positions[party2][mask]\n        \n        if len(positions1) > 0:  # Only calculate if we have valid positions\n            # Count where both agree:\n            # - both Eens\n            # - both Oneens\n            # - both Geen van beide\n            agreements = ((positions1 == 'Eens') & (positions2 == 'Eens')) | \\\n                        ((positions1 == 'Oneens') & (positions2 == 'Oneens')) | \\\n                        ((positions1 == 'Geen van beide') & (positions2 == 'Geen van beide'))\n            \n            # Calculate percentage\n            agreement_pct = (agreements.sum() / len(positions1)) * 100\n            \n            # Store in matrix using cleaned party names\n            agreement_matrix.iloc[i, j] = agreement_pct\n\n# Round to 1 decimal place\nagreement_matrix = agreement_matrix.round(1)\n```\n:::\n\n\nWe use a heatmap to visualize the result.\n\n::: {#ae67b6e1 .cell .column-screen-inset-right execution_count=11}\n``` {.python .cell-code}\nplt.figure(figsize=(15, 15))\nim = plt.imshow(agreement_matrix, cmap='RdYlBu', vmin=0, vmax=100)\nplt.colorbar(im, fraction=0.046, pad=0.04, label='Agreement %')\nplt.xticks(range(len(party_names)), party_names, rotation=90)\nplt.yticks(range(len(party_names)), party_names)\nplt.title('Percentage of issues on which parties agree')\n\n# Add percentage text to each cell\nfor i in range(len(party_names)):\n    for j in range(len(party_names)):\n        text = plt.text(j, i, f'{agreement_matrix.iloc[i, j]}%',\n                       ha='center', va='center')\n        \nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-12-output-1.png){width=1429 height=1292}\n:::\n:::\n\n\nCells show % agreement. The 100% values on the main diagonal are expected, as a party always agrees with its own answers.\n\n## What parties are the most and the least in agreement with each other?\n\nIgnoring the 100% self-agreement, what are the highest and lowest agreement pairs?\n\n::: {#19df1ba0 .cell execution_count=12}\n``` {.python .cell-code}\nmin_agreement = agreement_matrix.values.min()\n\n# Find the second largest unique agreement value\nunique_agreements = np.unique(agreement_matrix.values)\nif len(unique_agreements) > 1:\n    max_agreement = unique_agreements[-2]\nelse:\n    max_agreement = unique_agreements[0]\n\nprint(f\"Minimal agreement percentage: {min_agreement}%\")\nprint(f\"Maximal agreement percentage: {max_agreement}%\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nMinimal agreement percentage: 13.3%\nMaximal agreement percentage: 93.3%\n```\n:::\n:::\n\n\nThese are the parties with highest agreement levels:\n\n::: {#58dafe58 .cell execution_count=13}\n``` {.python .cell-code}\n# Find all party pairs with the second largest agreement\nsecond_max_pairs = []\nfor i in range(len(party_names)):\n    for j in range(i + 1, len(party_names)):\n        if agreement_matrix.iloc[i, j] == max_agreement:\n            second_max_pairs.append((party_names[i], party_names[j]))\n\nfor p1, p2 in second_max_pairs:\n    print(f\"{p1} ❤️ {p2}: {max_agreement}%\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nBIJ1 ❤️ Piratenpartij: 93.3%\n```\n:::\n:::\n\n\nThe parties with the lowest agreement levels are:\n\n::: {#b3e5ade9 .cell execution_count=14}\n``` {.python .cell-code}\n# Find party pairs for min_agreement\nparty_pairs = []\nfor i in range(len(party_names)):\n    for j in range(i + 1, len(party_names)):\n        value = agreement_matrix.iloc[i, j]\n        if value == min_agreement:\n            party_pairs.append((party_names[i], party_names[j]))\n\nfor p1, p2 in party_pairs:\n    print(f\"{p1} 💔 {p2}: {min_agreement}%\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFvD 💔 GroenLinks-PvdA: 13.3%\nPVV 💔 Volt: 13.3%\n```\n:::\n:::\n\n\nWe have to take into consideration that the statements on the Stemwijzer website are chosen such that we can differentiate between parties. It's likely that on many issues, seemingly very dissimilar parties like the FvD and GroenLinks-PvdA, actually agree with each other. It wouldn't make sense to use those issues as statements for Stemwijzer as they wouldn't help a voter distinguish between parties.\n\n## Squeezing 30 issues into 2D using t-SNE\n\nBy encoding *Eens* (agree) as 1, *Oneens* (disagree) as -1, and *Geen van beide* (neutral) as 0, we transform each party's stance into a quantifiable, 30-dimensional vector.\n\n::: {#dfef994d .cell execution_count=15}\n``` {.python .cell-code}\npd.set_option('future.no_silent_downcasting', True)\n\n# Create encoded dataframe by mapping positions to numerical values\nposition_mapping = {\n    'Eens': 1.0,\n    'Oneens': -1.0,\n    'Geen van beide': 0.0\n}\n\n# Get only the position columns and convert to numeric values\nposition_cols = [col for col in df_position.columns if col.endswith('_position')]\ndf_encoded = df_position[position_cols].copy()\ndf_encoded = df_encoded.replace(position_mapping)\n\n# Convert to float64\ndf_encoded = df_encoded.astype('float64')\n```\n:::\n\n\nWe can now project the parties into 2D using **t-SNE** (t-distributed Stochastic Neighbor Embedding).\n\nThe idea behind t-SNE is that local neighborhoods are reserved by making sure that points close together in original space stay close in 2D. \n\nLet's run it to see if clusters emerge.\n\n::: {#e8165c9c .cell .column-page-inset-right execution_count=16}\n``` {.python .cell-code}\n# Prepare the encoded party positions\nX = df_encoded.values\n\n# Run t-SNE\ntsne = TSNE(n_components=2, random_state=4, perplexity=5)\nX_embedded = tsne.fit_transform(X.T)  # transpose so shape is (n_parties, n_issues)\n\n# Plot the parties in 2D space\nplt.figure(figsize=(10, 10))\n\n# Add party logos and points\nfor i, name in enumerate(party_names):\n    # Add the scatter point\n    plt.scatter(X_embedded[i, 0], X_embedded[i, 1], color='white', edgecolor='black', s=100)\n    \n    # Add the party logo\n    if name in party_logos:\n        imagebox = OffsetImage(party_logos[name], zoom=0.25)\n        ab = AnnotationBbox(imagebox, (X_embedded[i, 0], X_embedded[i, 1]),\n                          frameon=False,\n                          box_alignment=(0.5, 0.5))\n        plt.gca().add_artist(ab)\n    \n    # Add party name below the logo\n    plt.text(X_embedded[i, 0], X_embedded[i, 1] - 5.5, name, \n             fontsize=8, ha='center', va='top')\n\nplt.title('t-SNE visualization of party positions')\nplt.xlabel('t-SNE dimension 1')\nplt.ylabel('t-SNE dimension 2')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-17-output-1.png){width=948 height=948}\n:::\n:::\n\n\nNothing too surprising here. Parties that were similar in the heatmap above seem to lie closer together in this t-SNE plot as well. Two shortcomings of t-SNE are that it sometimes creates artificial spacing and that axes don't really represent anything. Different runs produce different projections.\n\n## Doing a Principal Component Analysis (PCA)\n\n**PCA** (Principal Component Analysis) finds orthogonal axes capturing maximal variance. In contrast to t-SNE, axes *do* have somewhat interpretable meanings. Early components might capture broad ideological splits. Let's see if this is the case.\n\n::: {#eda403c6 .cell .column-page-inset-right execution_count=17}\n``` {.python .cell-code}\n# Prepare the encoded party positions (already created in cell 13)\nX = df_encoded.values\n\n# Run PCA\npca = PCA(n_components=2, random_state=42)\nX_pca = pca.fit_transform(X.T)  # transpose so shape is (n_parties, n_issues)\n\n# Plot the parties in 2D space\nplt.figure(figsize=(10, 10))\nfor i, name in enumerate(party_names):\n    plt.scatter(X_pca[i, 0], X_pca[i, 1])\n\n    # Add the party logo\n    if name in party_logos:\n        imagebox = OffsetImage(party_logos[name], zoom=0.25)\n        ab = AnnotationBbox(imagebox, (X_pca[i, 0], X_pca[i, 1]),\n                          frameon=False,\n                          box_alignment=(0.5, 0.5))\n        plt.gca().add_artist(ab)\n    \n    # Add party name below the logo\n    plt.text(X_pca[i, 0], X_pca[i, 1] - 0.20, name, \n             fontsize=8, ha='center', va='top')\n\nplt.title('PCA visualization of party positions')\nplt.xlabel('PCA dimension 1')\nplt.ylabel('PCA dimension 2')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-18-output-1.png){width=949 height=948}\n:::\n:::\n\n\nAt first glance PC1 looks like a left–right axis, but we’ll validate that by inspecting which *issues* load strongly on it. PC2 might reflect a libertarian–authoritarian or progressive–traditional divide. We'll try to interpret these components below.\n\n## How much variance do components capture?\n\nThe scree plot below shows how much variance is explained by each principal component (PC).\n\n::: {#5e19f8cd .cell .column-page-inset-right execution_count=18}\n``` {.python .cell-code}\n# Fit PCA with all possible components (up to number of parties)\npca_full = PCA(n_components=len(position_cols), random_state=42)\nX = df_encoded.values\npca_full.fit(X.T)  # shape: (n_parties, n_issues)\n\n# Explained variance ratio for each component\nexplained_variance = pca_full.explained_variance_ratio_\n\n# Plot the explained variance ratio\nplt.figure(figsize=(8, 5))\nplt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', label='Individual')\nplt.plot(range(1, len(explained_variance) + 1), explained_variance.cumsum(), marker='s', label='Cumulative')\nplt.xlabel('Number of PCA components')\nplt.ylabel('Explained variance ratio')\n\n# Annotate each bar with the percentage of explained variance\nfor i, v in enumerate(explained_variance):\n    plt.text(i + 1, v + 0.005, f\"{v*100:.1f}%\", ha='center', va='bottom', fontsize=9)\nplt.bar(range(1, len(explained_variance) + 1), explained_variance, color='skyblue')\nplt.legend().remove()\nplt.title('Explained variance by PCA components')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-19-output-1.png){width=757 height=468}\n:::\n:::\n\n\nMost variance is captured by PC1 (38.2%). Explanatory power then drops quickly, but PC2 still captures 13.3% of the variance.\n\n## Interpreting the axes\n\nLet's look at the loading scores of the first two PCs.\n\n::: {#763dcceb .cell .column-screen-inset-right execution_count=19}\n``` {.python .cell-code}\n# Get PCA loadings (components) for each issue on each factor\n# Create DataFrame with loadings scaled by explained variance\nloadings = pd.DataFrame(\n    data=pca.components_.T * np.sqrt(pca.explained_variance_), \n    columns=[f\"PC{i}\" for i in range(1, pca.n_components_ + 1)],\n    index=df_position['theme']\n)\n\nfig, axs = plt.subplots(2, 1, figsize=(10, 8), sharex=True, sharey=True)\ncolors = [\"#1C3041\", \"#9B1D20\"]\n\nfor i, ax in enumerate(axs):\n    if i >= pca.n_components_:\n        ax.axis('off')\n        continue\n        \n    explained_variance = pca.explained_variance_ratio_[i] * 100\n    pc = f\"PC{i+1}\"\n    bars = ax.bar(range(len(loadings.index)), loadings[pc], color=colors[i], edgecolor=\"#000000\", linewidth=1.2)\n    ax.set_title(f\"{pc} Loading Scores ({explained_variance:.2f}% Explained Variance)\", fontdict={\"weight\": \"bold\"}, pad=20)\n    if i == len(axs) - 1:  # Only add xlabel to the bottom subplot\n        ax.set_xlabel(\"Thema\")\n    ax.set_ylabel(\"Loading Score\")\n    ax.grid(axis=\"y\")\n    ax.set_xticks(range(len(loadings.index)))\n    if i == len(axs) - 1:  # Only add x-tick labels to the bottom subplot\n        ax.set_xticklabels(loadings.index, rotation=90, ha='right', fontsize=9)\n    ax.set_ylim(-1, 1)\n    \n    for j, bar in enumerate(bars):\n        yval = bar.get_height()\n        if abs(yval) > 0.1:  # Only show labels for significant values\n            offset = yval + 0.02 if yval > 0 else yval - 0.02\n            ax.text(bar.get_x() + bar.get_width() / 2, offset, f\"{yval:.2f}\", \n                   ha=\"center\", va=\"bottom\" if yval > 0 else \"top\", fontsize=7)\n\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-20-output-1.png){width=941 height=757}\n:::\n:::\n\n\nStrong loadings tell us which statements \"pull\" most on a component and can help us discover underlying ideological factors.\n\nLet's look at the five strongest _absolute_ loadings of PC1 and PC2.\n\n::: {#2fae1a50 .cell execution_count=20}\n``` {.python .cell-code}\n# Get absolute loadings for PC1 and PC2\npc1_loadings = loadings['PC1'].abs()\npc2_loadings = loadings['PC2'].abs()\n\n# Get top 5 themes for each component\ntop5_pc1 = pc1_loadings.sort_values(ascending=False).head(5)\ntop5_pc2 = pc2_loadings.sort_values(ascending=False).head(5)\n\nprint(\"Top 5 most important themes for PC1:\")\nfor theme in top5_pc1.index:\n    print(f\"- {theme} (loading: {loadings.loc[theme, 'PC1']:.2f})\")\n\nprint(\"\\nTop 5 most important themes for PC2:\")\nfor theme in top5_pc2.index:\n    print(f\"- {theme} (loading: {loadings.loc[theme, 'PC2']:.2f})\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTop 5 most important themes for PC1:\n- Illegaal verblijf (loading: 0.88)\n- Geld naar publieke omroep (loading: 0.87)\n- Minder stikstof (loading: -0.87)\n- Wolven (loading: 0.79)\n- Profileren op nationaliteit (loading: -0.77)\n\nTop 5 most important themes for PC2:\n- Leeftijdsgrens sociale media (loading: 0.65)\n- Sekswerk (loading: 0.61)\n- Aanwezigheid bij demonstratie (loading: 0.59)\n- Meer geld voor defensie (loading: 0.51)\n- Meer geld voor ontwikkelingshulp (loading: 0.51)\n```\n:::\n:::\n\n\nPC1 loads strongly on issues like immigration, environmental rules, and cultural liberalism. In the past, \"left\" and \"right\" mainly referred to views on how much the state should intervene in the market. Today, though, these terms also seem to cover social and cultural topics like immigration, religion, and the environment. So I would say that PC1 does indeed reflect a _Left-Right_ divide, however not the classic economic one.\n\nPC2 loads primarily on issues involving social regulation, moral permissiveness, and authority (e.g., restrictions on social media use, sex work, and protest). I would therefor interpret it as an _Libertarian-Authoritarian_ dimension, reflecting preferences for state control and traditional morality versus individual freedom and permissiveness.\n\n## Some final remarks\n\nI want to end this post with a few remarks, a disclaimer of sorts.\n\nI am not a political scientist. I tried to interpret the PCs to the best of my understanding, but someone more knowledgable might interpret the loading scores differently and come up with more accurate labels for the PCs.\n\nI don't know how the 30 issues on the Stemwijzer website are selected but it's unlikely that they are an accurate representation of a party's viewpoints. By reducing positions to three possible answers we lose any nuance in a party's stance. Furthermore, the 30 issues are selected in such a way that they are discriminative: They're meant to help you choose between parties. It's likely that parties are more similar than the distance matrix/heatmap above suggests.\n\nAnother thing to keep in mind is that when parties supply their positions to the Stemwijzer website, they likely do so strategically by aligning with what they _think_ most voters would prefer. They're trying to rake in votes and might misrepresent their actual stance on certain issues. Politicians can be manipulative and dishonest. Shocking, I know. \n\nDespite these shortcomings, I did find it insightful to see how the Stemwijzer data shows underlying _left-right_ and _libertarian-authoritarian_ axes. It helped me realize that my vote shouldn't just be about agreeing or disagreeing with a list of statements, but also about what level of left-right/libertarian-authoritarian I'm comfortable with.\n\nYou can find the code for both the analysis and webscraper in the following GitHub repository:\n\n<a target=\"_blank\" href=\"https://github.com/afvanwoudenberg/stemwijzer\">![GitHub](https://shields.io/badge/-View%20on%20GitHub-grey.svg?logo=github&style=flat&logoColor=white&labelColor=black)</a>\n\nDon't forget to vote!\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}